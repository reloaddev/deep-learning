{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "ds = load_dataset(\"dair-ai/emotion\", \"split\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "1    0.335125\n",
      "0    0.291625\n",
      "3    0.134937\n",
      "4    0.121063\n",
      "2    0.081500\n",
      "5    0.035750\n",
      "Name: proportion, dtype: float64\n",
      "label\n",
      "1    0.3475\n",
      "0    0.2905\n",
      "3    0.1375\n",
      "4    0.1120\n",
      "2    0.0795\n",
      "5    0.0330\n",
      "Name: proportion, dtype: float64\n",
      "label\n",
      "1    0.3520\n",
      "0    0.2750\n",
      "3    0.1375\n",
      "4    0.1060\n",
      "2    0.0890\n",
      "5    0.0405\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "### Task 1.1 ###\n",
    "# Extract class labels into list of integers\n",
    "\n",
    "train_df = ds[\"train\"].to_pandas()\n",
    "test_df = ds[\"test\"].to_pandas() \n",
    "validation_df = ds[\"validation\"].to_pandas()\n",
    "\n",
    "train_dist = train_df['label'].value_counts(normalize=True)\n",
    "test_dist = test_df['label'].value_counts(normalize=True)\n",
    "validation_dist = validation_df['label'].value_counts(normalize=True)\n",
    "\n",
    "print(train_dist)\n",
    "print(test_dist)\n",
    "print(validation_dist)\n",
    "\n",
    "# The class distribution is not balanced, but the balance is the\n",
    "# same across all three splitsacc=\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chance Levels\n",
      "Train:  0.2381384765625\n",
      "Test:  0.24400599999999997\n",
      "Validation:  0.23923250000000004\n"
     ]
    }
   ],
   "source": [
    "# What is the chance accuracy level?\n",
    "\n",
    "chance_level_train = (train_dist** 2).sum()\n",
    "chance_level_test = (test_dist ** 2).sum()\n",
    "chance_level_val = (validation_dist ** 2).sum()\n",
    "\n",
    "print(\"Chance Levels\")\n",
    "print(\"Train: \", chance_level_train)\n",
    "print(\"Test: \", chance_level_test)\n",
    "print(\"Validation: \", chance_level_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of classifier only predicting most common class:  0.08936666666666666\n"
     ]
    }
   ],
   "source": [
    "# What would be the accuracy of a classifier\n",
    "# that only predicts the most common class seen in training?\n",
    "\n",
    "print(\"Accuracy of classifier only predicting most common class: \", 5362/60000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Text Length - Range              : 293\n",
      "[Train] Text Length - Mean               : 96.8458125\n",
      "[Train] Text Length - Std                : 55.904952812332766\n",
      "[Test] Text Length - Range              : 282\n",
      "[Test] Text Length - Mean               : 96.5865\n",
      "[Test] Text Length - Std                : 55.71599100417033\n",
      "[Validation] Text Length - Range              : 284\n",
      "[Validation] Text Length - Mean               : 95.3475\n",
      "[Validation] Text Length - Std                : 54.82375913810559\n",
      "                                                text  label  \\\n",
      "0                            i didnt feel humiliated      0   \n",
      "1  i can go from feeling so hopeless to so damned...      0   \n",
      "2   im grabbing a minute to post i feel greedy wrong      3   \n",
      "3  i am ever feeling nostalgic about the fireplac...      2   \n",
      "4                               i am feeling grouchy      3   \n",
      "\n",
      "                                              tokens  \n",
      "0                       [i, didnt, feel, humiliated]  \n",
      "1  [i, can, go, from, feeling, so, hopeless, to, ...  \n",
      "2  [im, grabbing, a, minute, to, post, i, feel, g...  \n",
      "3  [i, am, ever, feeling, nostalgic, about, the, ...  \n",
      "4                          [i, am, feeling, grouchy]  \n"
     ]
    }
   ],
   "source": [
    "### Task 1.2 ###\n",
    "# Analyze the distribution of text lengths by providing its range, mean and standard deviation.\n",
    "\n",
    "splits = [\n",
    "    {\"label\": \"Train\", \"df\": train_df},\n",
    "    {\"label\": \"Test\", \"df\": test_df},\n",
    "    {\"label\": \"Validation\", \"df\": validation_df}\n",
    "]\n",
    "for split in splits:    \n",
    "    text_lengths = split[\"df\"][\"text\"].map(lambda x: len(x))\n",
    "    text_lengths_range = text_lengths.max() - text_lengths.min()\n",
    "    print(f\"[{split['label']}] Text Length - Range              :\", text_lengths_range)\n",
    "    text_lengths_mean = text_lengths.mean()\n",
    "    print(f\"[{split['label']}] Text Length - Mean               :\", text_lengths_mean)\n",
    "    text_lengths_std = text_lengths.std()\n",
    "    print(f\"[{split['label']}] Text Length - Std                :\", text_lengths_std)\n",
    "\n",
    "\n",
    "# Extract the texts for all splits and split each text into tokens.\n",
    "import torchtext\n",
    "from torchtext.data import get_tokenizer\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "\n",
    "train_df[\"tokens\"] = train_df[\"text\"].apply(lambda x: tokenizer(x))\n",
    "test_df[\"tokens\"] = test_df[\"text\"].apply(lambda x: tokenizer(x))\n",
    "validation_df[\"tokens\"] = validation_df[\"text\"].apply(lambda x: tokenizer(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Task 1.3 ###\n",
    "# Build a vocabulary (map string to integer) based on train split\n",
    "from collections import Counter\n",
    "import torch\n",
    "\n",
    "counter = Counter()\n",
    "for sample in train_df[\"tokens\"]:\n",
    "    counter.update(sample)\n",
    "vocabulary = {\n",
    "    '<UNK>': 0,\n",
    "    '<PAD>': 1,\n",
    "    **{word: idx + 2 for idx, (word, count) in enumerate(counter.most_common(1000))}   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 40, 101, 60, 8, 15, 494, 5, 15, 0, 553, 32, 60, 61, 128, 148, 76, 0, 4, 22, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "### Task 1.4 ###\n",
    "# Encode all texts with the defined vocabulary\n",
    "# value 0 resembles <UNK> (unknown token)\n",
    "# value 1 resemples <PAD> (padding token)\n",
    "\n",
    "# Sequences shorter than max_length, will be filled\n",
    "# up with <PAD> until they match max_length\n",
    "def pad_sequence(sequence, max_length=100, pad_value=1):\n",
    "    if len(sequence) > max_length:\n",
    "        return sequence[:max_length]\n",
    "    else:\n",
    "        return sequence + [pad_value] * (max_length - len(sequence))\n",
    "\n",
    "# Encode and pad all texts with the defined vocabulary\n",
    "train_sequences = [pad_sequence([vocabulary.get(token, 0) for token in sample]) for sample in train_df[\"tokens\"]]\n",
    "test_sequences = [pad_sequence([vocabulary.get(token, 0) for token in sample]) for sample in test_df[\"tokens\"]]\n",
    "validation_sequences = [pad_sequence([vocabulary.get(token, 0) for token in sample]) for sample in validation_df[\"tokens\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Task 1.5a ###\n",
    "# Convert lists into tensors\n",
    "def vectorize_sequences(sequences, samples, vocabulary):\n",
    "    one_hot_results = torch.zeros(len(samples), len(vocabulary) + 1)\n",
    "    for idx, sequence in enumerate(sequences):\n",
    "        one_hot_results[idx, sequence] = 1\n",
    "    return one_hot_results\n",
    "\n",
    "train_data = vectorize_sequences(train_sequences, train_df[\"text\"],vocabulary)\n",
    "test_data = vectorize_sequences(test_sequences, test_df[\"text\"],vocabulary)\n",
    "validation_data = vectorize_sequences(validation_sequences, validation_df[\"text\"],vocabulary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Task 1.5b ###\n",
    "# Load the data\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, sequences, labels):\n",
    "        self.sequences = sequences\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.sequences[idx], dtype=torch.long), torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "# Assuming you have labels in your DataFrame\n",
    "train_labels = train_df[\"label\"].tolist()\n",
    "test_labels = test_df[\"label\"].tolist()\n",
    "validation_labels = validation_df[\"label\"].tolist()\n",
    "\n",
    "# Create dataset instances\n",
    "train_dataset = TextDataset(train_sequences, train_labels)\n",
    "test_dataset = TextDataset(test_sequences, test_labels)\n",
    "validation_dataset = TextDataset(validation_sequences, validation_labels)\n",
    "\n",
    "# Create DataLoader instances\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
