{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "ds = load_dataset(\"dair-ai/emotion\", \"split\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000\n",
      "4000\n",
      "4000\n",
      "<class 'pandas.core.series.Series'>\n",
      "label\n",
      "1    0.3475\n",
      "0    0.2905\n",
      "3    0.1375\n",
      "4    0.1120\n",
      "2    0.0795\n",
      "5    0.0330\n",
      "Name: proportion, dtype: float64\n",
      "label\n",
      "1    0.3520\n",
      "0    0.2750\n",
      "3    0.1375\n",
      "4    0.1060\n",
      "2    0.0890\n",
      "5    0.0405\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "### Task 1.1 ###\n",
    "# Extract class labels into list of integers\n",
    "\n",
    "train_df = ds[\"train\"].to_pandas()\n",
    "test_df = ds[\"test\"].to_pandas() \n",
    "validation_df = ds[\"validation\"].to_pandas()\n",
    "\n",
    "print(train_df.size)\n",
    "print(test_df.size)\n",
    "print(validation_df.size)\n",
    "\n",
    "train_dist = train_df['label'].value_counts(normalize=True)\n",
    "test_dist = test_df['label'].value_counts(normalize=True)\n",
    "validation_dist = validation_df['label'].value_counts(normalize=True)\n",
    "\n",
    "print(type(train_dist))\n",
    "print(test_dist)\n",
    "print(validation_dist)\n",
    "\n",
    "# The class distribution is not balanced, but the balance is the\n",
    "# same across all three splitsacc=\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chance Levels\n",
      "Train:  0.2381384765625\n",
      "Test:  0.24400599999999997\n",
      "Validation:  0.23923250000000004\n"
     ]
    }
   ],
   "source": [
    "# What is the chance accuracy level?\n",
    "\n",
    "chance_level_train = (train_dist** 2).sum()\n",
    "chance_level_test = (test_dist ** 2).sum()\n",
    "chance_level_val = (validation_dist ** 2).sum()\n",
    "\n",
    "print(\"Chance Levels\")\n",
    "print(\"Train: \", chance_level_train)\n",
    "print(\"Test: \", chance_level_test)\n",
    "print(\"Validation: \", chance_level_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of classifier only predicting most common class:  0.338025\n"
     ]
    }
   ],
   "source": [
    "# What would be the accuracy of a classifier\n",
    "# that only predicts the most common class seen in training?\n",
    "\n",
    "print(\"Accuracy of classifier only predicting most common class: \", 13521/40000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Text Length - Range              : 293\n",
      "[Train] Text Length - Mean               : 96.8458125\n",
      "[Train] Text Length - Std                : 55.904952812332766\n",
      "[Test] Text Length - Range              : 282\n",
      "[Test] Text Length - Mean               : 96.5865\n",
      "[Test] Text Length - Std                : 55.71599100417033\n",
      "[Validation] Text Length - Range              : 284\n",
      "[Validation] Text Length - Mean               : 95.3475\n",
      "[Validation] Text Length - Std                : 54.82375913810559\n"
     ]
    }
   ],
   "source": [
    "### Task 1.2 ###\n",
    "# Analyze the distribution of text lengths by providing its range, mean and standard deviation.\n",
    "\n",
    "splits = [\n",
    "    {\"label\": \"Train\", \"df\": train_df},\n",
    "    {\"label\": \"Test\", \"df\": test_df},\n",
    "    {\"label\": \"Validation\", \"df\": validation_df}\n",
    "]\n",
    "for split in splits:    \n",
    "    text_lengths = split[\"df\"][\"text\"].map(lambda x: len(x))\n",
    "    text_lengths_range = text_lengths.max() - text_lengths.min()\n",
    "    print(f\"[{split['label']}] Text Length - Range              :\", text_lengths_range)\n",
    "    text_lengths_mean = text_lengths.mean()\n",
    "    print(f\"[{split['label']}] Text Length - Mean               :\", text_lengths_mean)\n",
    "    text_lengths_std = text_lengths.std()\n",
    "    print(f\"[{split['label']}] Text Length - Std                :\", text_lengths_std)\n",
    "\n",
    "\n",
    "# Extract the texts for all splits and split each text into tokens.\n",
    "def whitespace_tokenizer(text):\n",
    "    split = text.split()\n",
    "    return [token.strip().lower() for token in text.split()]\n",
    "\n",
    "train_df[\"tokens\"] = train_df[\"text\"].apply(lambda x: whitespace_tokenizer(x))\n",
    "test_df[\"tokens\"] = test_df[\"text\"].apply(lambda x: whitespace_tokenizer(x))\n",
    "validation_df[\"tokens\"] = validation_df[\"text\"].apply(lambda x: whitespace_tokenizer(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Task 1.3 ###\n",
    "# Build a vocabulary (map string to integer) based on train split\n",
    "from collections import Counter\n",
    "import torch\n",
    "\n",
    "counter = Counter()\n",
    "for sample in train_df[\"tokens\"]:\n",
    "    counter.update(sample)\n",
    "vocabulary = {\n",
    "    '<UNK>': 0,\n",
    "    '<PAD>': 1,\n",
    "    **{word: idx + 2 for idx, (word, count) in enumerate(counter.most_common(1000))}   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Task 1.4 ###\n",
    "# Encode all texts with the defined vocabulary\n",
    "# value 0 resembles <UNK> (unknown token)\n",
    "# value 1 resemples <PAD> (padding token)\n",
    "\n",
    "# Sequences shorter than max_length, will be filled\n",
    "# up with <PAD> until they match max_length\n",
    "def pad_sequence(sequence, max_length=100, pad_value=1):\n",
    "    if len(sequence) > max_length:\n",
    "        return sequence[:max_length]\n",
    "    else:\n",
    "        return sequence + [pad_value] * (max_length - len(sequence))\n",
    "\n",
    "# Encode and pad all texts with the defined vocabulary\n",
    "train_sequences = [pad_sequence([vocabulary.get(token, 0) for token in sample]) for sample in train_df[\"tokens\"]]\n",
    "test_sequences = [pad_sequence([vocabulary.get(token, 0) for token in sample]) for sample in test_df[\"tokens\"]]\n",
    "validation_sequences = [pad_sequence([vocabulary.get(token, 0) for token in sample]) for sample in validation_df[\"tokens\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Task 1.5a ###\n",
    "# Convert lists into tensors\n",
    "def vectorize_sequences(sequences, samples, vocabulary):\n",
    "    one_hot_results = torch.zeros(len(samples), len(vocabulary) + 1)\n",
    "    for idx, sequence in enumerate(sequences):\n",
    "        one_hot_results[idx, sequence] = 1\n",
    "    return one_hot_results\n",
    "\n",
    "train_data = vectorize_sequences(train_sequences, train_df[\"text\"],vocabulary)\n",
    "test_data = vectorize_sequences(test_sequences, test_df[\"text\"],vocabulary)\n",
    "validation_data = vectorize_sequences(validation_sequences, validation_df[\"text\"],vocabulary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Task 1.5b ###\n",
    "# Load the data\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, sequences, labels):\n",
    "        self.sequences = sequences\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.sequences[idx], dtype=torch.long), torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "# Assuming you have labels in your DataFrame\n",
    "train_labels = train_df[\"label\"].tolist()\n",
    "test_labels = test_df[\"label\"].tolist()\n",
    "validation_labels = validation_df[\"label\"].tolist()\n",
    "\n",
    "# Create dataset instances\n",
    "train_dataset = TextDataset(train_data, train_labels)\n",
    "test_dataset = TextDataset(test_data, test_labels)\n",
    "validation_dataset = TextDataset(validation_data, validation_labels)\n",
    "\n",
    "# Create DataLoader instances\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vocabulary' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 29\u001b[0m\n\u001b[1;32m     25\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(hidden_state_outputs)\n\u001b[1;32m     26\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m---> 29\u001b[0m vocab_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43mvocabulary\u001b[49m) \n",
      "\u001b[0;31mNameError\u001b[0m: name 'vocabulary' is not defined"
     ]
    }
   ],
   "source": [
    "### Task 2 ###\n",
    "# Design a model that is suitable for the task. Network 1 --> RNN\n",
    "import torch.nn as nn\n",
    "\n",
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim=100, hidden_size=128, num_layers=1, num_classes=6):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=1)  # PAD token index is 1\n",
    "        self.rnn = nn.GRU(input_size=embedding_dim, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 100)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(100, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.to(next(self.embedding.parameters()).device)  # Ensure x is on the same device as the embedding layer\n",
    "        x = self.embedding(x)  # Shape: (batch_size, max_length, embedding_dim)\n",
    "        # Initialize hidden state (ensure batch_size matches x.size(0))\n",
    "        h0 = torch.zeros(self.rnn.num_layers, x.size(0), self.rnn.hidden_size).to(x.device)\n",
    "        # Pass through RNN\n",
    "        out, hn = self.rnn(x, h0)\n",
    "        # Extract the last hidden state (last time step of the last layer)\n",
    "        hidden_state_outputs = out[:, -1, :]\n",
    "        # Pass through fully connected layers\n",
    "        hidden_state_outputs = self.fc(hidden_state_outputs)\n",
    "        result = self.fc2(hidden_state_outputs)\n",
    "        return result\n",
    "\n",
    "   \n",
    "vocab_size = len(vocabulary) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01moptim\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m GRUModel(vocab_size\u001b[38;5;241m=\u001b[39mvocab_size)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      7\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = GRUModel(vocab_size=vocab_size).to(device)\n",
    "\n",
    "epochs = 10\n",
    "learning_rate = 0.0001\n",
    "train_losses = []\n",
    "validation_losses = []\n",
    "train_accuracies = []\n",
    "validation_accuracies = []\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(pred.data, 1)\n",
    "        total += y.size(0)\n",
    "        correct += (predicted == y).sum().item()\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")\n",
    "            \n",
    "    train_losses.append(running_loss / len(dataloader))\n",
    "    train_accuracies.append(correct / total) \n",
    "\n",
    "\n",
    "def validation_loop(dataloader, model, loss_fn):\n",
    "    model.eval()\n",
    "    \n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    validation_loss, correct = 0, 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            validation_loss += loss_fn(pred, y).item()\n",
    "            _, predicted = torch.max(pred.data, 1)\n",
    "            correct += (predicted == y).sum().item()\n",
    "            total += y.size(0)\n",
    "            \n",
    "    validation_losses.append(validation_loss / num_batches)  # Average test loss\n",
    "    validation_accuracies.append(correct / total)\n",
    "\n",
    "    validation_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Validation Error: \\n Accuracy: {(100 * correct):>0.1f}%, Avg loss: {validation_loss:>8f} \\n\")\n",
    "\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    validation_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            validation_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    \n",
    "    validation_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100 * correct):>0.1f}%, Avg loss: {validation_loss:>8f} \\n\")\n",
    "\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t + 1}\\n-------------------------------\")\n",
    "    train_loop(train_loader, model, loss_fn, optimizer)\n",
    "    validation_loop(validation_loader, model, loss_fn)\n",
    "test(test_loader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
